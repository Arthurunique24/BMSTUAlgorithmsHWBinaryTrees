# Домашнее задание по Алгоритмам и структурам данных.
### МГТУ им. Баумана

    Цель работы - реализовать операции вставки, поиска, удаления, получения минимального и максимального элементов для АА-дерева и АВЛ-дерева. 
**Двоичное дерево поиска** — это двоичное дерево, для которого выполняются следующие дополнительные условия (свойства дерева поиска):

* Оба поддерева — левое и правое — являются двоичными деревьями поиска.
* У всех узлов левого поддерева произвольного узла X значения ключей данных меньше, нежели значение ключа данных самого узла X.
* У всех узлов правого поддерева произвольного узла X значения ключей данных больше либо равно, нежели значение ключа данных самого узла X.

Очевидно, данные в каждом узле должны обладать ключами, на которых определена операция сравнения меньше.

Как правило, информация, представляющая каждый узел, является записью, а не единственным полем данных. Однако это касается реализации, а не природы двоичного дерева поиска.

**Для целей реализации двоичное дерево поиска можно определить так:**

* Двоичное дерево состоит из узлов (вершин) — записей вида (data, left, right), где data — некоторые данные, привязанные к узлу, left и right — ссылки на узлы, являющиеся детьми данного узла — левый и правый сыновья соответственно. Для оптимизации алгоритмов конкретные реализации предполагают также определения поля parent в каждом узле (кроме корневого) — ссылки на родительский элемент.
* Данные (data) обладают ключом (key), на котором определена операция сравнения «меньше». В конкретных реализациях это может быть пара (key, value) — (ключ и значение), или ссылка на такую пару, или простое определение операции сравнения на необходимой структуре данных или ссылке на неё.
* Для любого узла X выполняются свойства дерева поиска: key[left[X]] < key[X] ≤ key[right[X]], то есть ключи данных родительского узла больше ключей данных левого сына и нестрого меньше ключей данных правого.

#### Базовый интерфейс двоичного дерева поиска состоит из трех операций:

* FIND(K) — поиск узла, в котором хранится пара (key, value) с key = K.
* INSERT(K,V) — добавление в дерево пары (key, value) = (K, V).
* REMOVE(K) — удаление узла, в котором хранится пара (key, value) с key = K.

### Стандартные операции в двоичном дереве поиска, одинаковые для АА-дерева и АВЛ-дереве

#### Search (Поиск)

*T - дерево, K - ключ*

Если дерево пусто, сообщить, что узел не найден, и остановиться.

Иначе сравнить K со значением ключа корневого узла X.
* Если K = X, выдать ссылку на этот узел и остановиться.
* Если K > X, рекурсивно искать ключ K в правом поддереве Т.
* Если K < X, рекурсивно искать ключ K в левом поддереве Т.

#### Min (Минимальное значение)
Так как в бинарном дереве поиска для каждого узла справедливо, что left < right, то соответственно для нахождения наименьшенго элемента  переходим всегда в левую ветку нашего дерева, пока не найдем минимальный элемент.

#### Max (Максимальное значение)
Аналогично с нахождением минимального значения использвуем, что left < right, и соответственно для нахождения наибольшего элемента  переходим всегда в правую ветку нашего дерева, пока не найдем максимальный элемент.

## АА-дерево

**АA-дерево** — структура данных, представляющая собой сбалансированное двоичное дерево поиска, которое является разновидностью красно-черного дерева с дополнительными ограничениями.

В своих работах *Arne Andersson* приводит простое правило, которому должно удовлетворять AA-дерево:
*к одной вершине можно присоединить другую вершину того же уровня но только одну и только справа.*

Таким образом, введенное понятие уровня вершины не всегда совпадает с реальной высотой вершины (расстояния от земли), но дерево сохраняет балансировку при следовании правилу «одна правая связь на одном уровне». 

```C++
struct node {
    int level; // уровень; 1 у листьев
    T key;  // ключ, данные связанные с вершиной
    node *right; // указатель на правого потомка
    node *left; // указатель на левого потомка
    node *parent; //указатель на родителя
};
```

#### Свойства АА-дерева

* Уровень каждого листа равен 1.
* Уровень каждого левого ребенка ровно на один меньше, чем у его родителя.
* Уровень каждого правого ребенка равен или на один меньше, чем у его родителя.
* Уровень каждого правого внука строго меньше, чем у его прародителя.
* Каждая вершина с уровнем больше 1 имеет двоих детей.

В отличие от красно-черных деревьев, к одной вершине можно присоединить вершину только того же уровня, только одну и только справа (другими словами, красные вершины могут быть добавлены только в качестве правого ребенка). На картинке ниже представлен пример красно-чёрного дерева.

*На практике в AA-дереве вместо значения цвета для балансировки дерева в вершине хранится информация только о ее уровне.*

В AA-дереве разрешены правые ребра, не идущие подряд, и запрещены все левые горизонтальные ребра. Эти более жесткие ограничения, аналогичные ограничениям на красно-черных деревьях, приводят к более простой реализации балансировки AA-дерева.

#### Балансировка

**Для балансировки АА-дерева нужны следующие две операции:**

**Skew** - устранение левого горизонтального ребра. Делаем правое вращение, чтобы заменить поддерево, содержащее левую горизонтальную связь, на поддерево, содержащее разрешенную правую горизонтальную связь.

**Split** - устранение двух последовательных правых горизонтальных ребер. Делаем левое вращение и увеличиваем уровень, чтобы заменить поддерево, содержащее две или более последовательных правильных горизонтальных связи, на вершину, содержащую два поддерева с меньшим уровнем.

#### Вставка вершины

Как и положено почти любому дереву поиска, вставляем новое значение среди листьев дерева (приписывая ему минимальную высоту). Потом вызываем Split (вернее Split(Skew()) ) для всех узлов по пути от листа до корня. Чем имтируем обычное расщепление 2-3 узлов.

#### Удаление вершины

Сначала мы находим узел, который надо удалить, потом находим минимальное (или максимальное - не важно) значение в одной из его веток, и ставим его на замену удалённому узлу. Всё как в обычном бинарном дереве поиска. На этом сходство с обычными 2-3 деревьями и RB-деревьями практически заканчивается. Вместо того чтобы делать слияние и расщепление узлов, мы стаскиваем все 2-3 узлы, от листа до корня, по цепочке, отчего все попавшиеся узлы сливаются с соседями, рядом с которыми они упали. Стаскиваются по правде не все узлы, а только те у которых после удаления или стаскивания, остался разрыв между уровнями. Т.е. это в чём-то похоже на набору с B-деревом, но это не так как это делают обычно. Поскольку уровень, который расположен за листьями тоже имеет какой-то номер, который ниже листьев, то удаление листа (а физически мы всегда удаляем листы), начинается с того что узел над листом, начал контактировать со слоем, который под листами, из-за этого появляется разрыв, и начинается стаскивание узлов.
После стаскивания мы вызываем Split для каждого узла и приводим дерево в подходящий вид.

#### Print

Выводим значения в дерево по уровням, слева направо, начиная с level 1.

#### Использование

Фактически АА-дерево - это самое быстрое (или одно из самых быстрых) бинарное дерево с простой реализацией (за счет уменьшения количества разбираемых случаев). 
В итоге АА-дерево можно использовать в любом месте, где необходима более быстрая и простая реализация красно-черного дерева.

#### Эффективность

Оценка на высоту деревьев соответствует оценке для красно-черного дерева, 2 * log(N), так как AA-дерево сохраняет структуру красно-черного дерева. Следовательно все операции происходят за O(log N), потому что в сбалансированном двоичном дереве поиска почти все операции реализуются за O(h). Скорость работы AA-дерева эквивалентна скорости работы красно-черного дерева, но так как в реализации вместо цвета обычно хранят «уровень» вершины, дополнительные расходы по памяти достигают байта.

## АВЛ-дерево

АВЛ-дерево — это прежде всего двоичное дерево поиска, ключи которого удовлетворяют стандартному свойству: ключ любого узла дерева не меньше любого ключа в левом поддереве данного узла и не больше любого ключа в правом поддереве этого узла. Это значит, что для поиска нужного ключа в АВЛ-дереве можно использовать стандартный алгоритм. Для простоты дальнейшего изложения будем считать, что все ключи в дереве целочисленны и не повторяются.

```c++
struct node {
    T data; //ключ, данные связанные с вершиной
    struct node *left; // указатель на левого потомка
    struct node *right; // указатель на правого потомка
};
```

Особенностью АВЛ-дерева является то, что оно является сбалансированным в следующем смысле: для любого узла дерева высота его правого поддерева отличается от высоты левого поддерева не более чем на единицу.

#### Баланировка 

Относительно АВЛ-дерева балансировкой вершины называется операция, которая в случае разницы высот левого и правого поддеревьев = 2, изменяет связи предок-потомок в поддереве данной вершины так, что разница становится <= 1, иначе ничего не меняет. Указанный результат получается вращениями поддерева данной вершины.

**Используются 4 типа вращений:**

* *Малое левое вращение* - данное вращение используется тогда, когда высота b-поддерева — высота L(находиться в a-поддереве) = 2  и высота С(находиться в b-поддереве) <= высота R(находиться в b-поддереве).
* *Большое левое вращение* - Данное вращение используется тогда, когда высота b-поддерева — высота L(находиться в a-поддереве) = 2 и высота c-поддерева(находиться в b-поддереве) > высота R(находиться в b-поддереве).
* *Малое правое вращение* - Данное вращение используется тогда, когда высота b-поддерева — высота R(находиться в a-поддереве) = 2 и высота С(находиться в b-поддереве) <= высота L(находиться в b-поддереве).
* *Большое правое вращение* Данное вращение используется тогда, когда высота b-поддерева — высота R(находиться в a-поддереве) = 2 и высота c-поддерева(находиться в b-поддереве) > высота L(находиться в b-поддереве).

В каждом случае достаточно просто доказать то, что операция приводит к нужному результату и что полная высота уменьшается не более чем на 1 и не может увеличиться. Также можно заметить, что большое левое вращение это композиция правого малого вращения и левого малого вращения. Из-за условия балансированности высота дерева О(log(N)), где N- количество вершин, поэтому добавление элемента требует O(log(N)) операций.

#### Вставка вершины

Вставка нового ключа в АВЛ-дерево выполняется, по большому счету, так же, как это делается в простых деревьях поиска: спускаемся вниз по дереву, выбирая правое или левое направление движения в зависимости от результата сравнения ключа в текущем узле и вставляемого ключа. Единственное отличие заключается в том, что при возвращении из рекурсии (т.е. после того, как ключ вставлен либо в правое, либо в левое поддерево, и это дерево сбалансировано) выполняется балансировка текущего узла. Строго доказывается, что возникающий при такой вставке дисбаланс в любом узле по пути движения не превышает двух, а значит применение вышеописанной функции балансировки является корректным.

#### Удаление вершины

Для простоты опишем рекурсивный алгоритм удаления. Если вершина — лист, то удалим её и вызовем балансировку всех её предков в порядке от родителя к корню. Иначе найдём самую близкую по значению вершину в поддереве наибольшей высоты (правом или левом) и переместим её на место удаляемой вершины, при этом вызвав процедуру её удаления.

Докажем, что данный алгоритм сохраняет балансировку. Для этого докажем по индукции по высоте дерева, что после удаления некоторой вершины из дерева и последующей балансировки высота дерева уменьшается не более, чем на 1. База индукции: Для листа очевидно верно. Шаг индукции: Либо условие балансированности в корне (после удаления корень может изменится) не нарушилось, тогда высота данного дерева не изменилась, либо уменьшилось строго меньшее из поддеревьев => высота до балансировки не изменилась => после уменьшится не более чем на 1.

Очевидно, что в результате указанных действий процедура удаления вызывается не более 3 раз, так как у вершины, удаляемой по второму вызову, нет одного из поддеревьев. Но поиск ближайшего каждый раз требует O(N) операций. Становится очевидной возможность оптимизации: поиск ближайшей вершины может быть выполнен по краю поддерева, что сокращает сложность до O(log(N)).

#### Эффективность

Из формулы, приведённой выше, высота АВЛ-дерева никогда не превысит высоту идеально сбалансированного дерева более, чем на 45%. Для больших n имеет место оценка 1.04 log2n. Таким образом, выполнение основных операций требует порядка log2n сравнений. Экспериментально выяснено, что одна балансировка приходится на каждые 2 включения и на каждые 5 исключений.

#### Print

**Я предлагаю 3 способа вывода АВЛ-дерева:** 

(На выбор преподавателя. Будут реалихованы все)
Имеется у нас такое дерево.

                        15
                        
                11
                
                        8
                        
                                6
5

                        4
                        
                3
                
                        2
                        
                        

* *InOrder traversal. Вывод: 2  3  4  5  6  8  11  15 (обойти всё дерево, следуя порядку (левое поддерево, вершина, правое поддерево). Элементы по возрастанию) *

* *PreOrder traversal. Ввод: 5  3  2  4  11  8  6  15 (обойти всё дерево, следуя порядку (вершина, левое поддерево, правое поддерево). Элементы, как в дереве) *

* *PostOrder traversal. Вывод: 2  4  3  6  8  15  11  5 (обойти всё дерево, следуя порядку (левое поддерево, правое поддерево', вершина). Элементы в обратном порядке, как в дереве) *

#### Использование 

Можно быстро находить элементы массива ближайшие к заданному, но меньше его, или больше – для некоторых задач очень актуально.
АВЛ-дерево можно использовать, для сортировки массива из N элементов, так как можно его просто добавить в дерево – N*log(N) а потом обойти слева направо – N т.е. суммарное время N*log(N) – и мы сделали очередной очень быстрый метод сортировки массива

В общем случае использование АВЛ-дерева сводиться к сортировке массивов и списков, использание для проверки существования элементов в массиве, хранения индексов БД, сортировки им результатов поиска, в конце концов, его даже можно напрямую писать в файл и считывать для еще большего ускорения. 

## Формат данных

Входной файл содержит последовательность команд, т.е. представляет набор строк вида

**command [key] [data]**

где *command* — *add*, *delete*, *search*, *min*, *max*, *print* или *спец. команда*;

key — ключ, целое число; 

data — данные, целое число. 

**Примеры:**

*add 10 20* 

*search 15* 

*print*

*min*

#### Формат выходных данных

На выходе программы получаем оценку корректности всех алгоритмов, реальную оценку времени, затраченного на выполнение команды и объем использованной при этом памяти.

#### Реализация тестов

Время выполнения каждой операции будем вычислять при помощи стандартных библиотек. Для каждого дерева беруться одни и те же данные. Засекается время начала исполнения и конца исполнения операции, после чего берем разницу. Операция проделывается много раз, затем при помощи математического анализа высчитывается погрешность и соответственно максимально точное время.

#### План выполнения домашнего задания 

1. Реализовать АА-дерево.
2. Реализовать АВЛ-дерево.
3. Написать тесты стандартным операциям в двоичном дереве поиска. (Search, Min, Max)
4. Написать тесты к основным методам АА-дерева. (Вставка, удаление, вывод)
5. Написать тесты к основным методам АВЛ-дерева. (Вставка, удаление, вывод)
6. Оценить достаточно ли данных тестов для сравнения структур.
7. Доработать тесты при необходимости и поправить последние баги.
8. Повторить пункты 6 и 7. 
9. Проанализировать полученные результаты и написать вывод. 
10. Оформить отчет.
